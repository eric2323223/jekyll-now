# æ·±å…¥æµ…å‡ºç­–ç•¥æ¢¯åº¦(Policy Gradient)

å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ˜¯ä¸€ç±»ç”¨äºŽå¤æ‚åœºæ™¯çš„å­¦ä¹ ç®—æ³•ï¼Œè¢«å¹¿æ³›åº”ç”¨åœ¨æœºå™¨æŽ§åˆ¶ä»»åŠ¡ã€‚è¿‘å‡ å¹´æ¥ï¼Œéšç€ç¥žç»ç½‘ç»œçš„é‡æ–°å…´èµ·ï¼Œå¼ºåŒ–å­¦ä¹ ä¹Ÿè¢«é€æ¸åº”ç”¨åœ¨ä¸€äº›æ–°çš„é¢†åŸŸï¼Œæ¯”å¦‚è‡ªåŠ¨é©¾é©¶ï¼Œè®¡ç®—æœºè§†è§‰ç­‰ã€‚Alpha GO æˆ˜èƒœäººç±»æ£‹æ‰‹æ ‡å¿—ç€æœºå™¨å­¦ä¹ ç‰¹åˆ«æ˜¯å¼ºåŒ–å­¦ä¹ æ­£åœ¨æˆä¸ºé€æ¸æˆç†Ÿå¹¶èƒ½å¤Ÿå¤„ç†æ›´åŠ å¤æ‚çš„é—®é¢˜ï¼Œæˆä¸ºç ”ç©¶çš„çƒ­ç‚¹ï¼Œä¹Ÿè¢«è®¤ä¸ºèƒ½å¤Ÿåœ¨æœªæ¥åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå–å¾—çªç ´çš„æ–¹å‘ä¹‹ä¸€ã€‚æœ¬æ–‡æ—¨åœ¨ä»‹ç»å¼ºåŒ–å­¦ä¹ ä¸­æ¢¯åº¦ç­–ç•¥ï¼ˆPGï¼‰çš„åŸºæœ¬åŽŸç†ï¼Œç›¸å…³æ¦‚å¿µï¼Œå¹¶ç€é‡ä»‹ç»ä½œè€…åœ¨å­¦ä¹ PGè¿‡ç¨‹ä¸­é‡åˆ°çš„ä¸€äº›éš¾ç‚¹å¦‚ç†è§£ç›®æ ‡å‡½æ•°å’Œå®žçŽ°æŠ€æœ¯ã€‚


# ç›¸å…³æ¦‚å¿µ

## å¼ºåŒ–å­¦ä¹ 
Alpha GOæˆ˜èƒœäººç±»è®©å¤§ä¼—æƒŠå¹äºŽäººå·¥æ™ºèƒ½çš„çªé£žçŒ›è¿›çš„åŒæ—¶ï¼Œä¹Ÿè®©äººä¸ç¦å¥½å¥‡æœºå™¨å­¦ä¹ åˆ°åº•æ˜¯å¦‚ä½•å®žçŽ°å¯¹äººç±»çš„è¶…è¶Šï¼Œä¸€æ–¹é¢ç›‘ç£å¼å­¦ä¹ (supervised learning)çš„æ•ˆæžœå—é™äºŽè®­ç»ƒæ•°æ®ï¼Œ å¦ä¸€æ–¹é¢é‡‡ç”¨ç®€å•ç©·ä¸¾çš„æ–¹å¼ä¼šé‡åˆ°ç¡¬ä»¶çš„é™åˆ¶ï¼ˆå›´æ£‹çš„çŠ¶æ€ç»„åˆç©ºé—´$10^{360}$è¾¾åˆ°äº†å®‡å®™ç²’å­çš„æ•°é‡çº§ï¼‰ã€‚å…¶å®žAlpha GOçš„ä¸€ä¸ªç§˜å¯†æ­¦å™¨å°±æ˜¯ä»Šå¤©çš„ä¸»è§’-å¼ºåŒ–å­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ç±»æ–¹æ³•ã€‚~~ç®€å•çš„è¯´ï¼Œè¿™ç±»æ–¹æ³•é€šè¿‡å’ŒçŽ¯å¢ƒçš„äº¤äº’èŽ·å¾—åé¦ˆï¼Œå†æ ¹æ®åé¦ˆè¿›è¡Œä¼˜åŒ–ã€‚~~å¼ºåŒ–å­¦ä¹ è¯žç”ŸäºŽä¸Šä¸–çºª80å¹´ä»£ï¼Œå¼€å§‹åº”ç”¨äºŽåˆ¶é€ ä¸šï¼Œç‰¹åˆ«æ˜¯å·¥ä¸šæœºå™¨äººçš„è‡ªåŠ¨æŽ§åˆ¶ï¼Œè¿‘å¹´æ¥éšç€å…¶ä»–æœºå™¨æ–¹æ³•çš„æµè¡Œå¼€å§‹åº”ç”¨äºŽæ›´åŠ â€œæ™ºèƒ½â€çš„åœºæ™¯ï¼Œé™¤äº†å¤§åé¼Žé¼Žçš„Alpha GOï¼Œgoogle deepmindå›¢é˜Ÿè¿˜åº”ç”¨å¼ºåŒ–å­¦ä¹ å®žçŽ°äº†è®¡ç®—æœºè‡ªä¸»å­¦ä¹ çŽ©Atariç³»åˆ—ç”µå­æ¸¸æˆå¹¶è¶…è¶Šäº†äººç±»ä¸‡å®¶çš„æ°´å¹³ï¼Œ**ã€‚è¶Šæ¥è¶Šå¤šæˆåŠŸçš„åº”ç”¨è¡¨æ˜Žå¼ºåŒ–å­¦ä¹  ---
### Markov Decision Process (MDP)
ä¸åŒäºŽç›‘ç£å¼å­¦ä¹ é€šè¿‡æ ‡ç­¾æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ é€šè¿‡å’ŒçŽ¯å¢ƒäº¤äº’æ¥å­¦ä¹ ã€‚çŽ¯å¢ƒä¸€èˆ¬è¢«å½¢å¼åŒ–çš„æè¿°ä¸ºMDPï¼Œç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š
-   **$S$** : çŠ¶æ€é›†ï¼ŒSet of states. At each time step the state of the environment is an element  $s \in  S$.
-   **$A$**: åŠ¨ä½œé›† Set of actions. At each time step the agent choses an action  $a \in  A$ to perform.
-   **$p(s_{t+1} | s_t, a_t)$** : State transition model that describes how the environment state changes when the user performs an action  `a`depending on the action  `a`and the current state st.
-   **$p(r_{t+1} | s_t, a_t)$** : Reward model that describes the real-valued reward value that the agent recieves from the environment after performing an action. In MDP the the reward value depends on the current state and the action performed.
-  **ð›¾** : æŠ˜æ‰£ç³»æ•°ï¼Œç”¨äºŽè°ƒæ•´æœªæ¥å¯¹å½“å‰çš„å½±å“

å¼ºåŒ–å­¦ä¹ çš„è¿‡ç¨‹æ˜¯ä¸€ä¸ªé€šè¿‡å’ŒçŽ¯å¢ƒäº¤äº’èŽ·å¾—åé¦ˆï¼Œå†æ ¹æ®è¿”å›žè°ƒæ•´ä»¥æœŸä½¿æ€»å¥–åŠ±æœ€å¤§åŒ–çš„è¿‡ç¨‹ï¼Œè¿™ä¸ªæ˜¯ä¸€ä¸ªå¤šæ­¥çš„äº¤äº’çš„è¿‡ç¨‹ï¼Œæ¯ä¸€æ­¥äº¤äº’éƒ½ä¼šå½±å“å…¶åŽçš„æ‰€æœ‰æ­¥éª¤ã€‚å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€æ¬¡äº¤äº’æ˜¯æŒ‡Agent å¯¹çŽ¯å¢ƒæ–½åŠ ä¸€ä¸ªåŠ¨ä½œï¼Œè¿™ä¼šå¯¼è‡´å¯¼è‡´çŽ¯å¢ƒçš„çŠ¶æ€å‘ç”Ÿæ”¹å˜å¹¶ä¸”ç”±çŽ¯å¢ƒå›žé¦ˆç»™Agentä¸€ä¸ªå¥–åŠ±ï¼ˆå¥–åŠ±æ—¢å¯ä»¥æ˜¯æ­£å‘çš„ä¹Ÿå¯ä»¥æ˜¯è´Ÿå‘çš„ï¼‰ï¼Œå¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡å°±æ˜¯å¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜çš„ç­–ç•¥ä½¿å¾—æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹èŽ·å¾—çš„å¥–åŠ±æœ€å¤§åŒ–ã€‚


The way by which the agent choses which action to perform is named the agent  `policy`  which is a function that takes the current environment state to return an action. The policy is often denoted by the symbol ð›‘.
![](https://media.shellypalmer.com/wp-content/images/2016/03/alphago.jpg)
![](https://atariage.com/2600/hacks/screenshots/s_SpaceInvaders_RK_Hack_2.png)
å¼ºåŒ–å­¦ä¹ å®ƒåŒ…æ‹¬å¦‚ä¸‹å›¾æ‰€ç¤ºçš„å‡ ä¸ªéƒ¨åˆ†ï¼š
![](https://cdn-images-1.medium.com/max/1600/1*c3pEt4pFk0Mx684DDVsW-w.png)
1.  ä¸»ä½“(Agent) æŒ‡èƒ½å¤Ÿé€šè¿‡åŠ¨ä½œä¸ŽçŽ¯å¢ƒäº¤äº’çš„**ï¼Œåœ¨RLçš„çŽ¯å¢ƒä¸­ä¸»ä½“é€šå¸¸æ˜¯è¿è¡Œä¸­çš„ç®—æ³•ï¼Œæ¯”å¦‚åœ¨Atariæ¸¸æˆä¸­çš„ä¸»ä½“æ˜¯ç”¨äºŽæŽ§åˆ¶é£žèˆ¹çš„ç®—æ³•
2.  çŽ¯å¢ƒ(Environment) æŒ‡ä¸»ä½“åŠ¨ä½œä½œç”¨çš„å¯¹è±¡ï¼Œ æ¯”å¦‚Atariæ¸¸æˆæœ¬èº«ã€‚
3.  åŠ¨ä½œ (Action): æŒ‡æ‰€æœ‰å¯èƒ½çš„ä½œç”¨äºŽçŽ¯å¢ƒä¸Šçš„æ“ä½œï¼Œæ¯”å¦‚Atariæ¸¸æˆä¸­ç®—æ³•æŽ§åˆ¶é£žèˆ¹è¿›è¡Œç§»åŠ¨æˆ–å°„å‡»ã€‚
4.  çŠ¶æ€ (State): æŒ‡å¯è¢«ä¸»ä½“æ„ŸçŸ¥çš„å…³äºŽçŽ¯å¢ƒçš„ä¿¡æ¯ï¼Œæ¯”å¦‚Atariæ¸¸æˆä¸­å±å¹•æ˜¾ç¤ºçš„æ‰€æœ‰ç‰©ä½“çš„ä½ç½®ä»¥åŠç§»åŠ¨æ–¹å‘å’Œé€Ÿåº¦ä¿¡æ¯
5.  å¥–åŠ± (Reward): æŒ‡ç”±çŽ¯å¢ƒå›žé¦ˆç»™ä¸»ä½“çš„æè¿°ä¸Šä¸€ä¸ªåŠ¨ä½œæ•ˆæžœçš„ä¿¡æ¯ï¼Œæ¯”å¦‚Atariæ¸¸æˆä¸­é£žèˆ¹åŠ¨ä½œå¯¼è‡´çš„å¾—åˆ†å˜åŒ–ã€‚


åŒç›‘ç£å¼å­¦ä¹ ç±»ä¼¼ï¼Œå¼ºåŒ–å­¦ä¹ ä¹Ÿæ˜¯ä¸€ä¸ªé€šè¿‡å¤šä¸ªè½®æ¬¡é€æ¸ä¼˜åŒ–ç®—æ³•å‚æ•°æ¥å¢žå¼ºå­¦ä¹ æ•ˆæžœçš„è¿‡ç¨‹ï¼Œæ¯ä¸ªè½®æ¬¡åŒ…å«ä¸¤éƒ¨åˆ†ï¼šå‰å‘ä¼ é€’å’Œåå‘ä¼ é€’ã€‚å¤„äºŽåˆå§‹çŠ¶æ€çš„Agentæ ¹æ®ç®—æ³•çš„å½“å‰å‚æ•°ç”ŸæˆåŠ¨ä½œä½œç”¨äºŽçŽ¯å¢ƒï¼ŒçŽ¯å¢ƒè¿”å›žç»™Agentæ–°çš„çŠ¶æ€å’Œå¯¹åŠ¨ä½œçš„å¥–åŠ±ï¼Œåœ¨è½®æ¬¡ç»“æŸåŽç®—æ³•é€šè¿‡æ±‡æ€»æ‰€æœ‰åœ¨æœ¬è½®æ”¶é›†åˆ°çš„åé¦ˆè°ƒæ•´ç®—æ³•çš„å‚æ•°å¼€å§‹ä¸‹ä¸€è½®çš„å­¦ä¹ ï¼Œç›´åˆ°å­¦ä¹ çš„æ•ˆæžœä¸å†å¢žé•¿ã€‚å¸¸è§çš„å¼ºåŒ–å­¦ä¹ æœ‰ä¸¤ç±»ï¼šåŸºäºŽå€¼çš„æ–¹æ³•å’ŒåŸºäºŽç­–ç•¥çš„æ–¹æ³•ã€‚
## åŸºäºŽå€¼çš„æ–¹æ³•

åŸºäºŽå€¼çš„æ–¹æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯æ±‚ä¸€ä¸ªå‡½æ•°Qæ»¡è¶³bellmanæ–¹ç¨‹ï¼Œä½¿å¾—åœ¨çŠ¶æ€$s$ä¸‹ä½¿ç”¨åŠ¨ä½œ$a$å¯èƒ½å¾—åˆ°æœ€å¤§çš„å¥–åŠ±
$$
Q(s,a) = r + \gamma max_{a'} Q(s', a')
$$
å…¶ä¸­ï¼Œ$s'$è¡¨ç¤ºåœ¨å½“å‰çŠ¶æ€$s$ä¸‹ä½¿ç”¨åŠ¨ä½œ$a$å¾—åˆ°çš„ä¸‹ä¸€ä¸ªçŠ¶æ€ï¼Œ$\gamma$è¡¨ç¤ºå¯¹æœªæ¥äº‹ä»¶çš„æŠ˜æ‰£çŽ‡ï¼Œbellmanæ–¹ç¨‹æè¿°äº†ä¸€ä¸ªé€’å½’çš„è®¡ç®—æ–¹æ³•ï¼Œå³$s$çŠ¶æ€åœ¨ä½¿ç”¨$a$åŠ¨ä½œå¾—åˆ°çš„æ€»å¥–åŠ±ç­‰äºŽå½“å‰çš„ç›´æŽ¥å¥–åŠ±$r$å’Œä¸‹ä¸€æ­¥åŠ¨ä½œ$a'$äº§ç”Ÿçš„æ€»å¥–åŠ±çš„å’Œã€‚ä»Žè¿™ä¸ªæ–¹ç¨‹å¯çŸ¥ï¼Œä¸ºäº†è®¡ç®—$s$çŠ¶æ€ä¸‹çš„æœ€å¤§å¥–åŠ±ï¼Œéœ€è¦æ±‚å¤„å…¶åŽæ‰€æœ‰çŠ¶æ€çš„æ€»å¥–åŠ±ï¼Œ~~å› æ­¤ç”±äºŽéœ€è¦ä¿å­˜æ‰€æœ‰çŠ¶æ€çš„å¥–åŠ±ï¼Œè¿™ç§æ–¹æ³•è¦æ±‚é—®é¢˜çš„çŠ¶æ€ç©ºé—´ä¸èƒ½å¤ªå¤§ã€‚~~
### åŸºäºŽç­–ç•¥çš„æ–¹æ³•

robot control, Boston Dynamics




# ç­–ç•¥æ¢¯åº¦ï¼ˆPGï¼‰
## PGçš„åŸºæœ¬åŽŸç†
DQNå¯ä»¥ç›´æŽ¥è®¡ç®—å¥–åŠ±ä»Žè€Œå¯ä»¥å¾—åˆ°æœ€ä¼˜è§£ï¼Œè¿™å¬ä¸ŠåŽ»å¾ˆä¸é”™ï¼Œä½†è¿™ç§ç¡®å®šæ€§(deterministic)çš„æ–¹æ³•æ°æ°æ— æ³•å¤„ç†ä¸€äº›åšå¼ˆé—®é¢˜ï¼Œæ¯”å¦‚çŽ©100æŠŠçŸ³å¤´å‰ªåˆ€å¸ƒçš„æ¸¸æˆï¼Œæœ€å¥½çš„è§£æ³•æ˜¯éšæœºçš„ä½¿ç”¨çŸ³å¤´ã€å‰ªåˆ€å’Œå¸ƒå¹¶å°½é‡ä¿è¯è¿™ä¸‰ç§æ‰‹åŠ¿å‡ºçŽ°çš„æ¦‚çŽ‡ä¸€æ ·ï¼Œå› ä¸ºä»»ä½•ä¸€ç§æ‰‹åŠ¿çš„æ¦‚çŽ‡é«˜äºŽå…¶ä»–æ‰‹åŠ¿éƒ½ä¼šè¢«å¯¹æ‰‹æ³¨æ„åˆ°å¹¶ä½¿ç”¨ç›¸åº”çš„æ‰‹åŠ¿èµ¢å¾—æ¸¸æˆã€‚ å†æ¯”å¦‚ä¸‹å›¾è¿™ä¸ªä¾‹å­ï¼š


é‡‡ç”¨DQNçš„æ–¹æ³•åœ¨ç¡®å®šçš„çŠ¶æ€ä¸‹å°†å¾—åˆ°ç¡®å®šçš„rewardï¼Œå› æ­¤åœ¨ä½¿ç”¨DQNæ–¹æ³•å†³å®šç°è‰²æ–¹æ ¼çš„ä¸‹ä¸€æ­¥ï¼ˆå·¦æˆ–å³ï¼‰å°†å¿…ç„¶ä¼šå¯¼è‡´bad resultã€‚äº‹å®žä¸Šå¾ˆå¤šå®žé™…çš„éƒ½æœ‰ç±»ä¼¼çš„ç‰¹å¾ï¼Œå³

~~ç”±æ­¤çœ‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§éžç¡®å®šæ€§çš„æ–¹æ³•æ¥~~
å¦å¤–ï¼Œæœ‰é™çš„çŠ¶æ€æ•°é‡ä¹Ÿæ˜¯ä½¿ç”¨DQNçš„ä¸€ä¸ªå¤§é—®é¢˜ï¼Œå› ä¸ºåŸºäºŽå€¼çš„æ–¹æ³•éœ€è¦ä¿å­˜çŠ¶æ€è¡¨ï¼ˆæ‰€æœ‰çŠ¶æ€-åŠ¨ä½œçš„å¯¹åº”å…³ç³»ï¼‰ï¼Œå› æ­¤å¾ˆå¤šçŽ°å®žé—®é¢˜ï¼ˆä¾‹å¦‚æœºå™¨äººæŽ§åˆ¶å’Œè‡ªåŠ¨é©¾é©¶éƒ½æ˜¯è¿žç»­åŠ¨ä½œç©ºé—´ï¼‰ï¼Œéƒ½å› ä¸ºå·¨é‡çš„çŠ¶æ€è€Œæ— æ³•è®¡ç®—ã€‚
é‚£ä¹ˆå¦‚ä½•è§£å†³ä¸Šé¢çš„ä¸¤ä¸ªé—®é¢˜å‘¢ï¼Ÿæœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•èƒ½åœ¨ç¡®å®šçš„çŠ¶æ€ä¸‹å¾—åˆ°ä¸åŒçš„åŠ¨ä½œå‘¢ï¼Ÿåˆæœ‰ä»€ä¹ˆæ–¹æ³•èƒ½é¿å…ç»´æŠ¤åºžå¤§çš„çŠ¶æ€è¡¨å‘¢ï¼Ÿ
ç®€å•æ¥è¯´ï¼ŒPGåˆ™é‡‡å–äº†éšæœºï¼ˆstochasticï¼‰çš„æ–¹å¼è§£å†³äº†ä¸Šè¿°2ä¸ªé—®é¢˜ã€‚é¦–å…ˆéšæœºèƒ½æä¾›éžç¡®å®šçš„ç»“æžœï¼Œä½†è¿™ç§éžç¡®å®šçš„ç»“æžœå¹¶ä¸æ˜¯å®Œå…¨çš„éšæœºè€Œæ˜¯æœä»ŽæŸç§æ¦‚çŽ‡åˆ†å¸ƒçš„éšæœºï¼ŒPGä¸è®¡ç®—rewardè€Œæ˜¯ä»¥ç›´æŽ¥ä½¿ç”¨ç­–ç•¥é€‰æ‹©actionï¼Œè¿™æ ·å°±é¿å…äº†å› ä¸ºè®¡ç®—å¥–åŠ±è€Œç»´æŠ¤çŠ¶æ€è¡¨ã€‚ 
é‚£ä¹ˆPGçš„å­¦ä¹ åˆ°åº•æ˜¯æ€Žæ ·çš„å‘¢ï¼Ÿåœ¨è§£é‡Šè¿™ä¸ªè¿‡ç¨‹ä¹‹å‰å…ˆä»‹ç»å‡ ä¸ªæ¦‚å¿µï¼š
**å¯¹è±¡ç³»ç»Ÿ**ï¼šå°±æ˜¯PGçš„å­¦ä¹ å¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡å³å¯ä»¥æ˜¯ä¸€ä¸ªç³»ç»Ÿï¼Œæ¯”å¦‚æ±½è½¦æˆ–ä¸€ä¸ªæ¸¸æˆï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå¯¹æ‰‹ï¼Œæ¯”å¦‚åŠ¿å¤´å‰ªåˆ€å¸ƒçš„æ¸¸æˆå¯¹æ‰‹æˆ–è€…ä¸€ä¸ªèŒä¸šçš„å›´æ£‹æ‰‹ã€‚
~~MDP:Reward function~~
**Policyç­–ç•¥** $\pi_\theta(a|s)$ è¡¨ç¤ºåœ¨çŠ¶æ€$s$å’Œå‚æ•°$\theta$æ¡ä»¶ä¸‹å‘ç”ŸåŠ¨ä½œ$a$çš„æ¦‚çŽ‡
**Episodeè½®æ¬¡**: è¡¨ç¤ºä»Žèµ·å§‹çŠ¶æ€å¼€å§‹ä½¿ç”¨æŸç§ç­–ç•¥äº§ç”ŸåŠ¨ä½œä¸Žå¯¹è±¡ç³»ç»Ÿäº¤äº’ï¼Œç›´åˆ°æŸä¸ªç»ˆç»“çŠ¶æ€ç»“æŸã€‚æ¯”å¦‚åœ¨å›´æ£‹æ¸¸æˆä¸­çš„ä¸€ä¸ªè½®æ¬¡å°±æ˜¯ä»Žæ£‹ç›˜ä¸­çš„ç¬¬ä¸€ä¸ªè½å­å¼€å§‹ç›´åˆ°å¯¹å¼ˆåˆ†å‡ºèƒœè´Ÿï¼Œæˆ–è€…è‡ªåŠ¨é©¾é©¶çš„è½®æ¬¡æŒ‡ä»Žæ±½è½¦å¯åŠ¨ä¸€ç›´åˆ°é¡ºåˆ©æŠµè¾¾æŒ‡å®šçš„ç›®çš„åœ°ï¼Œå½“ç„¶æ’žè½¦æˆ–è€…å¼€è¿›æ°´å¡˜ä¹Ÿæ˜¯ç§ä¸ç†æƒ³çš„ç»ˆç»“çŠ¶æ€ã€‚
**Trajectoryè½¨è¿¹** $\tau$ è¡¨ç¤ºåœ¨PGä¸€ä¸ªè½®æ¬¡çš„å­¦ä¹ ä¸­çŠ¶æ€$s$ï¼ŒåŠ¨ä½œ$a$å’Œå¥–åŠ±$r$çš„é¡ºåºæŽ’åˆ—
$$
\tau = (s_0, a_0, r_0, s_1, a_1, r_1, ... , s_t, a_t, r_t)
$$
ç”±äºŽç­–ç•¥äº§ç”Ÿçš„æ˜¯éžç¡®å®šçš„åŠ¨ä½œï¼ŒåŒä¸€ä¸ªç­–ç•¥åœ¨å¤šä¸ªè½®æ¬¡å¯ä»¥äº§ç”Ÿå¤šä¸ªä¸åŒçš„è½¨è¿¹ã€‚~~å› æ­¤åœ¨å®žçŽ°ä¸­å¯¹æ¯ä¸ªç­–ç•¥ä¼šæ±‚å¤šä¸ªè½®æ¬¡çš„å¹³å‡å€¼~~

>å¦‚æžœAgentçš„æŸä¸ªè¡Œä¸ºç­–ç•¥å¯¼è‡´çŽ¯å¢ƒæ­£çš„å¥–èµ(å¼ºåŒ–ä¿¡å·)ï¼Œé‚£ä¹ˆAgentä»¥åŽäº§ç”Ÿè¿™ä¸ªè¡Œä¸ºç­–ç•¥çš„è¶‹åŠ¿ä¾¿ä¼šåŠ å¼ºã€‚Agentçš„ç›®æ ‡æ˜¯åœ¨æ¯ä¸ªç¦»æ•£çŠ¶æ€å‘çŽ°æœ€ä¼˜ç­–ç•¥ä»¥ä½¿æœŸæœ›çš„æŠ˜æ‰£å¥–èµå’Œæœ€å¤§ã€‚
å¼ºåŒ–å­¦ä¹ æŠŠå­¦ä¹ çœ‹ä½œè¯•æŽ¢è¯„ä»·è¿‡ç¨‹ï¼ŒAgenté€‰æ‹©ä¸€ä¸ªåŠ¨ä½œç”¨äºŽçŽ¯å¢ƒï¼ŒçŽ¯å¢ƒæŽ¥å—è¯¥åŠ¨ä½œåŽçŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼ŒåŒæ—¶äº§ç”Ÿä¸€ä¸ªå¼ºåŒ–ä¿¡å·(å¥–æˆ–æƒ©)åé¦ˆç»™Agentï¼ŒAgentæ ¹æ®å¼ºåŒ–ä¿¡å·å’ŒçŽ¯å¢ƒå½“å‰çŠ¶æ€å†é€‰æ‹©ä¸‹ä¸€ä¸ªåŠ¨ä½œï¼Œé€‰æ‹©çš„åŽŸåˆ™æ˜¯ä½¿å—åˆ°æ­£å¼ºåŒ–(å¥–)çš„æ¦‚çŽ‡å¢žå¤§ã€‚é€‰æ‹©çš„åŠ¨ä½œä¸ä»…å½±å“ç«‹å³å¼ºåŒ–å€¼ï¼Œè€Œä¸”å½±å“çŽ¯å¢ƒä¸‹ä¸€æ—¶åˆ»çš„çŠ¶æ€åŠæœ€ç»ˆçš„å¼ºåŒ–å€¼ã€‚
å¼ºåŒ–å­¦ä¹ ä¸åŒäºŽè¿žæŽ¥ä¸»ä¹‰å­¦ä¹ ä¸­çš„ç›‘ç£å­¦ä¹ ï¼Œä¸»è¦è¡¨çŽ°åœ¨æ•™å¸ˆä¿¡å·ä¸Šï¼Œå¼ºåŒ–å­¦ä¹ ä¸­ç”±çŽ¯å¢ƒæä¾›çš„å¼ºåŒ–ä¿¡å·æ˜¯Agentå¯¹æ‰€äº§ç”ŸåŠ¨ä½œçš„å¥½åä½œä¸€ç§è¯„ä»·(é€šå¸¸ä¸ºæ ‡é‡ä¿¡å·)ï¼Œè€Œä¸æ˜¯å‘Šè¯‰Agentå¦‚ä½•åŽ»äº§ç”Ÿæ­£ç¡®çš„åŠ¨ä½œã€‚ç”±äºŽå¤–éƒ¨çŽ¯å¢ƒæä¾›äº†å¾ˆå°‘çš„ä¿¡æ¯ï¼ŒAgentå¿…é¡»é è‡ªèº«çš„ç»åŽ†è¿›è¡Œå­¦ä¹ ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒAgentåœ¨è¡ŒåŠ¨ä¸€ä¸€è¯„ä»·çš„çŽ¯å¢ƒä¸­èŽ·å¾—çŸ¥è¯†ï¼Œæ”¹è¿›è¡ŒåŠ¨æ–¹æ¡ˆä»¥é€‚åº”çŽ¯å¢ƒã€‚
å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿå­¦ä¹ çš„ç›®æ ‡æ˜¯åŠ¨æ€åœ°è°ƒæ•´å‚æ•°ï¼Œä»¥è¾¾åˆ°å¼ºåŒ–ä¿¡å·æœ€å¤§ã€‚è‹¥å·²çŸ¥r/Aæ¢¯åº¦ä¿¡æ¯ï¼Œåˆ™å¯ç›´æŽ¥å¯ä»¥ä½¿ç”¨ç›‘ç£å­¦ä¹ ç®—æ³•ã€‚å› ä¸ºå¼ºåŒ–ä¿¡å·rä¸ŽAgentäº§ç”Ÿçš„åŠ¨ä½œAæ²¡æœ‰æ˜Žç¡®çš„å‡½æ•°å½¢å¼æè¿°ï¼Œæ‰€ä»¥æ¢¯åº¦ä¿¡æ¯r/Aæ— æ³•å¾—åˆ°ã€‚å› æ­¤ï¼Œåœ¨[å¼ºåŒ–å­¦ä¹ ](https://baike.baidu.com/item/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)ç³»ç»Ÿä¸­ï¼Œéœ€è¦æŸç§éšæœºå•å…ƒï¼Œä½¿ç”¨è¿™ç§éšæœºå•å…ƒï¼ŒAgentåœ¨å¯èƒ½åŠ¨ä½œç©ºé—´ä¸­è¿›è¡Œæœç´¢å¹¶å‘çŽ°æ­£ç¡®çš„åŠ¨ä½œã€‚


PGçš„å­¦ä¹ æ˜¯ä¸€ä¸ªç­–ç•¥çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œæœ€å¼€å§‹éšæœºçš„ç”Ÿæˆä¸€ä¸ªç­–ç•¥ï¼Œå½“ç„¶è¿™ä¸ªç­–ç•¥å¯¹å¯¹è±¡ç³»ç»Ÿä¸€æ— æ‰€çŸ¥ï¼Œæ‰€ä»¥ç”¨è¿™ä¸ªç­–ç•¥äº§ç”Ÿçš„åŠ¨ä½œä¼šä»Žå¯¹è±¡ç³»ç»Ÿé‚£é‡Œå¾ˆå¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªè´Ÿé¢å¥–åŠ±ï¼Œè¿™ä¸ªè¿‡ç¨‹å°±å¥½åƒæˆ‘ä»¬çš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥åœ¨é¢å¯¹ç¬”ç›´çš„è·¯é¢è€Œäº§ç”Ÿå³è½¬çš„åŠ¨ä½œå¯¼è‡´æ±½è½¦æ’žä¸Šè·¯è¾¹çš„è¡Œäººè¿™æ ·çš„ä¸¥é‡åŽæžœã€‚ä¸ºäº†æ›´å¥½çš„é©¾é©¶æ±½è½¦PGéœ€è¦ä¸æ–­çš„æ”¹å˜ç­–ç•¥ä»Žè€ŒèŽ·å¾—æ›´é«˜çš„è½®æ¬¡å¥–åŠ±ï¼ˆå®‰å…¨å¿«é€Ÿçš„åˆ°è¾¾ç›®çš„åœ°ï¼‰ï¼ŒPGåœ¨ä¸€è½®çš„å­¦ä¹ ä¸­ä½¿ç”¨åŒä¸€ä¸ªç­–ç•¥ç›´åˆ°è¯¥è½®ç»“æŸï¼Œé€šè¿‡æ¢¯åº¦ä¸Šå‡æ”¹å˜ç­–ç•¥å¹¶å¼€å§‹ä¸‹ä¸€è½®å­¦ä¹ ï¼Œå¦‚æ­¤å¾€å¤ç›´åˆ°è½®æ¬¡ç´¯è®¡å¥–åŠ±ä¸å†å¢žé•¿åœæ­¢ã€‚   ~~ä¸€ä¸ªä½¿å¾—actionçš„é€‰æ‹©æœä»Žä¸€å®šçš„æ¦‚çŽ‡åˆ†å¸ƒï¼Œé€šè¿‡ä½¿ç”¨è¿™ä¸ªç­–ç•¥å®Œæˆæ‰€æœ‰äº¤äº’ï¼Œè¿™å°±æŠŠä¸€ä¸ªå¤æ‚çš„å®žé™…é—®é¢˜è½¬åŒ–æˆäº†æ¦‚çŽ‡ä¼˜åŒ–é—®é¢˜~~
![enter image description here](https://github.com/eric2323223/ML/blob/dev/drafts/PG1.PNG?raw=true)
## PGçš„ç›®æ ‡å‡½æ•°
æ ¹æ®ä¸Šè¿°PGçš„åŸºæœ¬åŽŸç†ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠPGçš„ç›®æ ‡å½¢å¼åŒ–çš„æè¿°ä¸ºä»¥ä¸‹è¡¨è¾¾å¼

$$
J(\theta) = argmax_\theta \mathbb E[r_0+r_1+r_2+...+r_t|\pi_\theta]  
$$
å…¶ä¸­$\mathbb E[r_0+r_1+r_2+...+r_t|\pi_\theta]$è¡¨ç¤ºåœ¨ç­–ç•¥$\pi_\theta$æ¡ä»¶ä¸‹ä¸€è½®äº¤äº’ï¼ˆ$0$åˆ°$t$æ­¥ï¼‰ä¸­çš„ç´¯è®¡å¥–åŠ±çš„æœŸæœ›å€¼ï¼Œè¿™é‡Œæ˜¯æœŸæœ›è€Œä¸æ˜¯ç¡®å®šå€¼æ˜¯å› ä¸ºæ¯ä¸€æ­¥çš„å¥–åŠ±æ˜¯æ ¹æ®ç­–ç•¥å¾—åˆ°çš„æœŸæœ›å€¼è€Œä¸æ˜¯ç¡®å®šå€¼ã€‚ç”±äºŽ$r_i$å¯ä»¥ç”±$r(\tau_{i-1})$è®¡ç®—å¾—åˆ°ï¼Œå› æ­¤å¯ä»¥æŠŠç´¯è®¡å¥–åŠ±çš„æœŸæœ›å€¼å†™æˆå¦‚ä¸‹ï¼š

$$
J(\theta) = \mathbb E_{\tau\sim \pi_\theta(\tau)}[\sum_t r(\tau)] \approx \frac {1}{N}\sum_i\sum_t r(s_{i,t}, a_{i,t})
$$
æˆ‘ä»¬æŠŠå•ä¸ªè½®æ¬¡çš„ç´¯è®¡å¥–åŠ±ä½œä¸ºPGçš„ç›®æ ‡å‡½æ•°$J(\theta)$ï¼Œåˆ™PGçš„ç›®æ ‡å°±æ˜¯ç¡®å®šæž„æˆç­–ç•¥çš„å‚æ•°$\theta$ä½¿å¾—$J(\theta)$å–å¾—æœ€å¤§å€¼

$$
\theta ^* = argmax J(\theta)
$$
å›¾ç‰‡Intuition trajectories.

çŽ°åœ¨PGçš„å­¦ä¹ å°±å˜æˆäº†ä¸€ä¸ªå¯¹$J(\theta)$æ±‚æœ€å¤§å€¼çš„é—®é¢˜ï¼Œå’Œç›‘ç£å¼å­¦ä¹ ä¸­ä½¿ç”¨çš„æ¢¯åº¦ä¸‹é™(gradient descent)æ±‚æŸå¤±å‡½æ•°(loss function)çš„æœ€å°å€¼ç±»ä¼¼ï¼ŒPGä¸­ä½¿ç”¨æ¢¯åº¦ä¸Šå‡(gradient ascent)æ¥æ›´æ–°$\theta$ã€‚
æ ¹æ®æœŸæœ›å€¼çš„æ•°å­¦å®šä¹‰ï¼Œ

$$
J(\theta) = \mathbb E_{r\sim \pi_\theta(\tau)} [\sum r_\tau]= \int_\tau r(\tau)\pi_\theta(\tau) d\tau
$$
å¯¹è¿™ä¸ªç§¯åˆ†è¡¨è¾¾å¼æ±‚å¯¼æ•°ï¼Œ
$$
\nabla_\theta J(\theta) =  \nabla_\theta \int_\tau r(\tau)\pi_\theta(\tau) d\tau= \int_\tau r(\tau)\nabla_\theta \pi_\theta(\tau) d\tau
$$
ç”±äºŽ$\pi_\theta(\tau)$æœ¬èº«ä¾èµ–äºŽ$\theta$ï¼Œæˆ‘ä»¬æ— æ³•ç›´æŽ¥æ±‚å¯¼ï¼Œå› æ­¤è¦ä½¿ç”¨ä¸€ä¸ªå°æŠ€å·§ï¼Œæ ¹æ®$\nabla log f(x)=\frac {\nabla f(x)}{f(x)}$å¯å¾—ä¸‹å¼
$$
\nabla_\theta\pi_\theta(\tau) = \pi_\theta(\tau)\frac{\nabla_\theta\pi_\theta(\tau)}{\pi_\theta(\tau)}=\pi_\theta(\tau)\nabla_\theta log\pi_\theta(\tau)
$$
å› æ­¤
$$
\nabla_\theta J(\theta) =\int r(\tau)\nabla_\theta\pi_\theta(\tau)d\tau = \int r(\tau)\pi_\theta(\tau)\nabla_\theta log\pi_\theta(\tau)d\tau
$$
å†æ ¹æ®æœŸæœ›å€¼çš„å®šä¹‰ï¼Œ
$$
\nabla_\theta J(\theta) =\int r(\tau)\pi_\theta(\tau)\nabla_\theta log\pi_\theta(\tau)d\tau=\mathbb E_{\tau\sim\pi_\theta(\tau)}[\nabla_\theta log\pi_\theta(\tau)r(\tau)]
$$
ç”±äºŽï¼Œ
$$
log\pi_\theta(\tau) = logp(s_1) + \sum_{t=1}^Tlog\pi_\theta(a_t|s_t)+logp(s_{t+1}|s_t, a_t)
$$
$$
r(\tau)=\sum_{t=1}^Tr(s_t,a_t)
$$
å¯å¾—
$$
\nabla_\theta J(\theta) =\mathbb E_{\tau\sim\pi_\theta(\tau)}[(\sum_{t=1}^Tlog\pi_\theta(a_t|s_t))(\sum_{t=1}^Tr(s_t,a_t))]
$$
è¿˜éœ€è¦æŒ‡å‡ºçš„æ˜¯ä¸Šè¿°è¡¨è¾¾å¼æè¿°äº†å½“å‰ç­–ç•¥$\pi_\theta$é€šè¿‡ä¸€è½®èŽ·å¾—çš„å¯¼æ•°ï¼Œå‰é¢æˆ‘ä»¬å·²ç»æåˆ°è¿‡ç”±äºŽç­–ç•¥äº§ç”Ÿçš„æ˜¯éžç¡®å®šçš„åŠ¨ä½œï¼Œå› æ­¤ç›¸åŒç­–ç•¥åœ¨å¤šè½®æ¬¡ä¸­ä¼šäº§ç”Ÿä¸åŒçš„è½¨è¿¹ï¼Œä¸ºäº†é¿å…ä¸ªä½“çš„åå·®ï¼Œæˆ‘ä»¬éœ€è¦å¤šæ¬¡å–æ ·å¹¶åŽ»å‡å€¼æ¥æé«˜å‡†ç¡®æ€§ï¼Œæ‰€ä»¥ï¼Œ
$$
\nabla_\theta J(\theta) \approx \frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^Tlog\pi_\theta(a_{i,t}|s_{i,t}))(\sum_{t=1}^Tr(s_{i,t},a_{i,t}))]
$$
è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†å¯è®¡ç®—çš„ç›®æ ‡å‡½æ•°çš„å¯¼æ•°$\nabla J(\theta)$ï¼Œåœ¨è½®æ¬¡çš„åå‘ä¼ é€’(back propagation)ä¸­ä½¿ç”¨å­¦ä¹ çŽ‡$\alpha$ä¸Ž$\nabla J(\theta)$çš„ä¹˜ç§¯ä½œä¸ºå·®å€¼$\delta$æ›´æ–°$\theta$
$$
\theta = \theta + \alpha \nabla J(\theta)
$$
ä»¥ä¸Šä¸ºäº†æŽ¨å¯¼ç”¨äºŽåå‘ä¼ é€’çš„å¯è®¡ç®—çš„$\nabla J(\theta)$åˆ—å‡ºäº†å¾ˆå¤šè¡¨è¾¾å¼ï¼Œç›®çš„æ˜¯å¸®åŠ©è¯»è€…ç†è§£PGç®—æ³•å®žçŽ°ï¼Œå› ä¸ºåœ¨ä»£ç å®žçŽ°ä¸­ä¼šç›´æŽ¥ä½¿ç”¨~~è¡¨è¾¾å¼x~~è®¡ç®—$\nabla J(\theta)$ï¼Œå¦‚æžœç›´æŽ¥çœ‹ä»£ç è€Œä¸äº†è§£$\nabla J(\theta)$çš„å˜å½¢çš„è¯ææ€•ä¼šè§‰å¾—è´¹è§£ã€‚ä¸è¿‡ä»Ž$\nabla_\theta J(\theta)$å’Œ$\pi_\theta(\tau)$$r(\tau)$çš„åŸºæœ¬å…³ç³»è¿˜æ˜¯èƒ½å¤Ÿä½œå‡ºè¿™æ ·çš„ç›´è§‚è§£é‡Šï¼šå¦‚æžœå¥–åŠ±($r(\tau)$)æ¯”è¾ƒé«˜æ—¶ï¼Œç­–ç•¥($\pi_\theta(\tau)$)ä¼šå€¾å‘äºŽå¢žåŠ ç›¸åº”çš„åŠ¨ä½œçš„æ¦‚çŽ‡ï¼Œå¦‚æžœå¥–åŠ±æ¯”è¾ƒä½Žæ—¶ï¼Œç­–ç•¥ä¼šå€¾å‘äºŽé™ä½Žç›¸åº”åŠ¨ä½œçš„æ¦‚çŽ‡ã€‚ä»Žæœºå™¨å­¦ä¹ çš„åŽŸç†çš„è§’åº¦æ¥çœ‹ï¼ŒPGå’Œä¼ ç»Ÿçš„ç›‘ç£å¼å­¦ä¹ çš„å­¦ä¹ è¿‡ç¨‹è¿˜æ˜¯æ¯”è¾ƒç›¸ä¼¼çš„ï¼Œæ¯è½®æ¬¡éƒ½ç”±å‰å‘ä¼ é€’å’Œåå‘ä¼ é€’æž„æˆï¼Œå‰å‘ä¼ é€’è´Ÿè´£è®¡ç®—ç›®æ ‡å‡½æ•°ï¼Œåå‘ä¼ é€’è´Ÿè´£æ›´æ–°ç®—æ³•çš„å‚æ•°ï¼Œä¾æ­¤è¿›è¡Œå¤šè½®æ¬¡çš„å­¦ä¹ æŒ‡å¯¼å­¦ä¹ æ•ˆæžœç¨³å®šæ”¶æ•›ã€‚å”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œç›‘ç£å¼å­¦ä¹ çš„ç›®æ ‡å‡½æ•°ç›¸å¯¹ç›´æŽ¥ï¼Œå³ç›®æ ‡å€¼å’ŒçœŸå®žå€¼çš„å·®ï¼Œè¿™ä¸ªå€¼ä¸€æ¬¡å‰å‘ä¼ é€’å°±èƒ½å¾—åˆ°ï¼›è€ŒPGçš„ç›®æ ‡å‡½æ•°æºè‡ªè½®æ¬¡å†…æ‰€æœ‰å¾—åˆ°çš„å¥–åŠ±ï¼Œå¹¶ä¸”éœ€è¦è¿›è¡Œä¸€å®šçš„æ•°å­¦è½¬æ¢æ‰èƒ½è®¡ç®—ï¼Œå¦å¤–ç”±äºŽç”¨å–æ ·æ¨¡æ‹ŸæœŸæœ›ï¼Œä¹Ÿéœ€è¦å¯¹åŒä¸€å¥—å‚æ•°è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ é€’æ¥å¢žåŠ æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§ã€‚
figure: intuition

ä»Žå®žçŽ°è§’åº¦çœ‹ï¼ŒPGçš„å­¦ä¹ è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µ
1. **å–æ ·**	å¯¹å½“å‰ç­–ç•¥å–å¤šä¸ªè½¨è¿¹ç”¨ä»¥å‡†ç¡®è®¡ç®—ç›®æ ‡å‡½æ•°ï¼Œå–æ ·çš„è¿‡ç¨‹å°±æ˜¯ç”¨å½“å‰ç­–ç•¥è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ é€’å¹¶ä¿å­˜è½¨è¿¹
2. **è®¡ç®—$\nabla J(\theta)$**
3. **æ”¹è¿›ç­–ç•¥**	ä½¿ç”¨2è®¡ç®—å‡ºçš„$\nabla J(\theta)$æ›´æ–°$\theta$

ä¼ªå®žçŽ°
>function REINFORCE()
Initialize $\theta$ arbitrarily
for all episodes $(s_1, a_1, r_2, ... , s_{T-1}, a_{T-1})\sim \pi_\theta$ do
for t = 1 to T - 1 do
$\theta = \theta + \alpha\nabla log\pi_\theta(a_t, s_t)r(a_t, s_t)$
end for
end for
return $\theta$
end function

## PGçš„æ”¹è¿›

è™½ç„¶PGç†è®ºä¸Šèƒ½å¤„ç†åŸºäºŽå€¼çš„æ–¹æ³•æ— æ³•å¤„ç†çš„å¤æ‚é—®é¢˜ï¼Œä½†ç”±äºŽPGä¾èµ–æ ·æœ¬æ¥ä¼˜åŒ–ç­–ç•¥ï¼Œå¯¼è‡´è¿™ç§æ–¹æ³•å—æ ·æœ¬ä¸ªä½“å·®å¼‚å½±å“æœ‰æ¯”è¾ƒå¤§çš„æ–¹å·®ï¼Œå­¦ä¹ çš„æ•ˆæžœä¸å®¹æ˜“æŒç»­å¢žå¼ºå’Œæ”¶æ•›ã€‚ä¸€ä¸ªåŸºæœ¬çš„æ”¹è¿›æ€è·¯æ˜¯é€šè¿‡å‡å°‘æ— æ•ˆçš„å…ƒç´ æ¥é™ä½Žæ–¹å·®ï¼Œç”±äºŽå½“å‰çš„åŠ¨ä½œä¸ä¼šå¯¹è¿‡åŽ»çš„å¥–åŠ±äº§ç”Ÿå½±å“ï¼Œå› æ­¤å¯ä»¥å°†$\nabla_\theta J(\theta)$æ”¹å†™ä¸º
$$
\nabla_\theta J(\theta) \approx\frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^Tlog\pi_\theta(a_{i,t}|s_{i,t}))(\sum_{t'=t}^Tr(a_{i,t'}, s_{i, t'}))]
$$
æˆ‘ä»¬è¿˜å¯ä»¥å€Ÿé‰´MDPæŠ˜æ‰£ç³»æ•°çš„æ€æƒ³é™ä½Žæœªæ¥çš„å½±å“
$$
\nabla_\theta J(\theta) \approx\frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^Tlog\pi_\theta(a_{i,t}|s_{i,t}))(\sum_{t'=t}^T\gamma^{t'-t} r(a_{i,t'}, s_{i, t'}))]
$$

å¦å¤–ä¸€ä¸ªæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŸºå‡†(baseline)$b$å‡å°æ–¹å·®ï¼Œè¿™æ˜¯å› ä¸ºå®žé™…è®¡ç®—ä¸­äº§ç”Ÿçš„æ€»å¥–åŠ±å¹¶ä¸èƒ½å‡†ç¡®ä»£è¡¨è¿™ä¸ªç­–ç•¥çš„å¥½åç¨‹åº¦ï¼Œæ¯”å¦‚å½“å‰å·²ç»å¾—åˆ°äº†ä¸€ä¸ªè¾ƒå¥½çš„ç­–ç•¥ï¼Œè€Œåœ¨ä¸‹ä¸€è½®çš„å­¦ä¹ ä¸­ç”¨ä¸€ä¸ªä¸å¤ªå¥½çš„æ ·æœ¬ä¹Ÿèƒ½å¾—åˆ°ä¸€ä¸ªæ­£å‘çš„æ€»å¥–åŠ±$\sum r$ï¼ŒPGç®—æ³•ä¾ç„¶ä¼šç”±äºŽè¿™ä¸ªæ­£å‘çš„æ€»å¥–åŠ±è°ƒæ•´åŽŸæ¥çš„ç­–ç•¥è€Œå¯¼è‡´å­¦ä¹ æ•ˆæžœä¸‹é™ã€‚å¦‚æžœæœ‰ä¸€ä¸ªåŸºå‡†å€¼$b$ä½¿å¾—PGä¸ä¼šå‘ä½ŽäºŽåŸºå‡†å€¼çš„æ–¹å‘ç§»åŠ¨ï¼ˆ$\sum r - b >0$ï¼‰ï¼Œå°±å¯ä»¥æœ‰æ•ˆçš„é¿å…è¿™ç§é—®é¢˜ã€‚
æˆ‘ä»¬è¿˜å¯ä»¥è¯æ˜ŽåŸºå‡†å€¼çš„å¼•å…¥ä¸ä¼šå¯¹ç›®æ ‡å‡½æ•°é€ æˆå½±å“ï¼Œå³$\frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^Tlog\pi_\theta(a_{i,t}|s_{i,t}))(\sum_{t'=t}^Tr(a_{i,t'}, s_{i, t'})-b)]$æ˜¯å¯¹$\nabla_\theta J(\theta)$çš„æ— åä¼°è®¡(unbiased estimator)ï¼Œ å› ä¸º
$$
\mathbb E[\nabla_\theta log\pi(\tau)b]=\int \pi_\theta(\tau)\nabla_\ log _\theta(\tau)bd\tau=\int \pi_\theta(\tau)\nabla_\theta(\tau)bd\tau = b\nabla_\theta\int \pi_\theta(\tau)d\tau
$$
ç”±äºŽ$\pi()$æ˜¯æ¦‚çŽ‡å¯†åº¦å‡½æ•°$\int \pi_\theta(\tau)d\tau=1$ï¼Œå› æ­¤
$$
\mathbb E[\nabla_\theta log\pi(\tau)b] = b\nabla_\theta1=0
$$
æ‰€ä»¥
$$
\nabla_\theta J(\theta) \approx\frac{1}{N}\sum_{i=1}^N[(\sum_{t=1}^Tlog\pi_\theta(a_{i,t}|s_{i,t}))(\sum_{t'=t}^Tr(a_{i,t'}, s_{i, t'})-b)]
$$
å¸¸è§çš„åŸºå‡†å€¼æ˜¯å‡å€¼
$$
b=\frac{1}{N}\sum_{i=1}^N r(a_i, s_i)
$$
ç›®å‰ä¹Ÿæœ‰å¯¹åŸºå‡†å€¼è¿›è¡Œæ”¹è¿›çš„æ–¹æ³•ï¼Œæ¯”å¦‚Actor-Criticç®—æ³•ï¼Œå…¶åŸºæœ¬æ€æƒ³æ˜¯ä½¿ç”¨DQNè¿›è¡ŒåŸºå‡†å€¼çš„ä¼˜åŒ–ï¼Œç”±äºŽç¯‡å¹…æ‰€é™åˆ¶åœ¨è¿™é‡Œä¸å±•å¼€ä»‹ç»ã€‚

# æ€»ç»“

ä¸ªäººä½“ä¼šPGå¯ä»¥æ€»ç»“ä¸€ä¸ªå…³é”®è¯ï¼šæŠ½æ ·ï¼Œé€šè¿‡æŠ½æ ·æ¨¡æ‹Ÿç›®æ ‡å‡½æ•°ï¼Œé¿å…äº†éåŽ†ï¼Œç”±äºŽæŠ½æ ·å¯¼è‡´è¾ƒå¤§çš„æ–¹æŸ¥

----------





# Markdown extensions

StackEdit extends the standard Markdown syntax by adding extra **Markdown extensions**, providing you with some nice features.

> **ProTip:** You can disable ny **Markdown extension** in the **File properties** dialog.


## SmartyPants

SmartyPants converts ASCII punctuation characters into "smart" typographic punctuation HTML entities. For example:

|                |ASCII                          |HTML                         |
|----------------|-------------------------------|-----------------------------|
|Single backticks|`'Isn't this fun?'`            |'Isn't this fun?'            |
|Quotes          |`"Isn't this fun?"`            |"Isn't this fun?"            |
|Dashes          |`-- is en-dash, --- is em-dash`|-- is en-dash, --- is em-dash|


## KaTeX

You can render LaTeX mathematical expressions using [KaTeX](https://khan.github.io/KaTeX/):

The *Gamma function* satisfying $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$ is via the Euler integral

$$
\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt
$$

> You can find more information about **LaTeX** mathematical expressions [here](http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference).


## UML diagrams

You can render UML diagrams using [Mermaid](https://mermaidjs.github.io/). For example, this will produce a sequence diagram:

```mermaid
sequenceDiagram
Alice ->> Bob: Hello Bob, how are you?
Bob-->>John: How about you John?
Bob--x Alice: I am good thanks!
Bob-x John: I am good thanks!
Note right of John: Bob thinks a long<br/>long time, so long<br/>that the text does<br/>not fit on a row.

Bob-->Alice: Checking with John...
Alice->John: Yes... John, how are you?
```

And this will produce a flow chart:

```mermaid
graph LR
A[Square Rect] -- Link text --> B((Circle))
A --> C(Round Rect)
B --> D{Rhombus}
C --> D
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTU5Njk3NTQyOSwxNjU3NjIxNzM5XX0=
-->